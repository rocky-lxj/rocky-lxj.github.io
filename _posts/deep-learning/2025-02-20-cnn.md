---
layout: post
title: "CNN"
date: 2025-02-20 11:57:54 +0000
categories: []
tags: []
published: true
author : "rocky-lxj"
---
## 原理
CNN（Convolutional Neural Network，卷积神经网络）结构可以分为3层：卷积层、池化层和全连接层。

## 卷积层
卷积层（Convolutional Layer） ：主要作用是提取特征。

过程：一个过滤器（卷积核，Filter）来过滤图像各个小区域，从而得到各个小区域的特征。卷积层通过卷积核的过滤提取出图片中局部的特征，与人类视觉的特征提取类似。

### 卷积

![卷积](https://github.com/rocky-lxj/rocky-lxj.github.io/raw/main/src/img/deep-learning/cnn-juanji.gif)


### 权值共享
在卷积运算中采用权值共享可以有效减少需要求解的参数。权值共享是基于这样的一个合理的假设：如果一个特征在计算某个空间位置 (x1,y1)(x1,y1) 的时候有用，那么它在计算另一个不同位置 (x2,y2)(x2,y2) 的时候也有用。通俗地来讲，在一个卷积核在和一个n通道的特征图（为方便理解，这里可以暂时理解为3通道的RGB输入图像）进行卷积运算时，可以看作是用这个卷积核作为一个滑块去“扫”这个特征图，卷积核里面的数就叫权重，这个特征图每个位置是被同样的卷积核“扫”的，所以权重是一样的，也就是共享。
![权值共享](https://github.com/rocky-lxj/rocky-lxj.github.io/raw/main/src/img/deep-learning/quanzhigongxiang.png)

## 池化层

最大池化(Max Pooling)和平均池化(Mean Pooling)
通常在连续的卷积层之间会周期性地插入一个池化层（也称“汇聚”层）。它的作用是逐渐降低数据体的空间尺寸，这样的话就能减少网络中参数的数量，使得计算资源耗费变少，也能有效控制过拟合。池化这个操作比较简单，一般在上采样和下采样的时候用到，没有参数，不可学习。

普通池化操作常见的有最大池化(Max Pooling)和平均池化(Mean Pooling)。 其中，最常用的是最大池化，最常见的形式是使用尺寸2x2的滤波器，以步长为2来对每个深度切片进行降采样，将其中75%的激活信息都丢掉。对更大感受野进行池化需要的池化尺寸也更大，而且往往对网络有破坏性。平均池化历史上比较常用，但是现在已经很少使用了。因为实践证明，最大池化的效果比平均池化要好。尺寸为2×2、步长为2的最大池化核平均池化的示例如下图所示：
![池化](https://github.com/rocky-lxj/rocky-lxj.github.io/raw/main/src/img/deep-learning/chihua.png)


## 全连接(Full Connected)层
全连接层和常规神经网络中一样，它的本质其实就是矩阵乘法再加上偏差，输入一个(B, iC)的数据，权重为(iC, oC)，那么输出为(B, oC)，在多层感知机和分类模型最后一层常常见到。
![全连接](https://github.com/rocky-lxj/rocky-lxj.github.io/raw/main/src/img/deep-learning/quanlianjie.png)

参考文章
[【综述】一文读懂卷积神经网络(CNN)](https://zhuanlan.zhihu.com/p/561991816)
